{{- if .Values.customResourceDefinitions.create }}
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name:  microsoft-sql-server-streams.streaming.sneaksanddata.com
spec:
  group: streaming.sneaksanddata.com
  scope: Namespaced
  names:
    plural: microsoft-sql-server-streams
    singular: microsoft-sql-server-stream
    kind: MicrosoftSqlServerStream
    shortNames:
      - mssql-stream
  versions:
    - name: v1
      served: true
      storage: true
      additionalPrinterColumns:
        - name: Table
          type: string
          jsonPath: .spec.sourceSettings.table
        - name: Schema
          type: string
          jsonPath: .spec.sourceSettings.schema
        - name: Change Capture Interval
          type: string
          jsonPath: .spec.sourceSettings.changeCaptureIntervalSeconds
        - name: Target table name
          type: string
          jsonPath: .spec.sinkSettings.targetTableName
        - name: Phase
          type: string
          jsonPath: .status.phase
      subresources:
        status: {}
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              properties:
                suspended:
                  description: Suspended indicates whether the stream is suspended.
                  type: boolean
                tableProperties:
                  type: object
                  default:
                    partitionExpressions: []
                    sortedBy: []
                    parquetBloomFilterColumns: []
                    format: PARQUET
                  properties:
                    partitionExpressions:
                      type: array
                      items:
                        type: string
                      default: []
                    sortedBy:
                      type: array
                      items:
                        type: string
                      default: [ ]
                    parquetBloomFilterColumns:
                      type: array
                      items:
                        type: string
                      default: [ ]
                    format:
                      type: string
                      enum:
                        - PARQUET
                        - ORC
                        - AVRO
                      default: PARQUET
                sourceSettings:
                  type: object
                  properties:
                    schema:
                      type: string
                      description: The schema where the source table resigns.
                    table:
                      type: string
                      description: The table to stream changes from.
                    changeCaptureIntervalSeconds:
                      type: integer
                      description: How long to wait before polling for next change set. Accepted range is between 1s and 3600s
                      minimum: 1
                      maximum: 3600
                    fetchSize:
                      type: integer
                      description: |
                        Gives the JDBC driver a hint as to the number of rows that should be fetched from the database when more rows are needed.
                        This is an advanced setting and it should not be changed under normal circumstances. You might want to experiment with increasing it if the source server is able to prepare data for transmit really fast, 
                        AND when table is at least 100 columns wide. This can also be increased when doing backfill of a large source table, to increase data throughput rate on source side (as long as network allows).
                        
                        If the stream causes performance issues on the source server side, try lowering this to 8 instead.
                      default: 128
                    buffering:
                      type: object
                      properties:
                        strategy:
                          type: string
                          enum:
                            - unbounded
                            - bounded
                        maxBufferSize:
                          type: integer
                          description: The maximum number of rows to buffer before sending to the sink.
                      description: |
                        Sets the buffering strategy for the source. Which allows the source to run independently of
                        the sink in parallel. Has two strategies:
                        
                          - unbounded: The source will run independently of the sink and will not wait for the sink to
                                       process the data. In this case the source will buffer it's output to the unbounded buffer.
                                       This strategy can significantly increase both the memory usage by the pod and the throughput
                                       of the stream, which can be desirable for backfill jobs.
                                       This is the default strategy for backfill jobs.
                        
                          - bounded: The source will run independently of the sink and will not wait for the sink to
                                     process the data. In this case the source will buffer it's output to the bounded buffer.
                                     If the buffer is full, the source will wait for the sink to process the data before
                                     continuing. If this strategy is used the maxBufferSize must be set.
                        
                        By default Arcane uses unbounded buffering for backfill jobs and does not use buffering for
                        the streaming jobs.
                connectionStringRef:
                  description: |
                    Name of the secret containing the JDBC connection string to the source SQL Server. If you are connecting over public network, you should enable encryption by adding `encrypt=true`
                    The secret should have a key named 'ARCANE_CONNECTIONSTRING'.
                  type: object
                  properties:
                    name:
                      type: string
                jobTemplateRef:
                  description: |
                    Name of the job template to be used for the application in streaming mode.
                  type: object
                  properties:
                    name:
                      type: string
                    kind:
                      type: string
                    apiGroup:
                      type: string
                  default:
                    apiGroup: streaming.sneaksanddata.com
                    kind: StreamingJobTemplate
                    name: standard-job
                backfillJobTemplateRef:
                  description: |
                    Name of the job template to be used for the for the application in backfill mode.
                  type: object
                  properties:
                    name:
                      type: string
                    kind:
                      type: string
                    apiGroup:
                      type: string
                  default:
                    apiGroup: streaming.sneaksanddata.com
                    kind: StreamingJobTemplate
                    name: large-job
                rowsPerGroup:
                  type: integer
                  description: Maximum number of rows to be grouped together for the staging process to consume.
                groupingIntervalSeconds:
                  type: integer
                  description: Max time to wait for rowsPerGroup to accumulate and then proceed to staging. Can be from 1 to 60 seconds.
                  minimum: 1
                  maximum: 3600
                sinkSettings:
                  type: object
                  properties:
                    optimizeSettings:
                      type: object
                      description: Configuration for target table optimize (data file aggregation into bigger files)
                      properties:
                        batchThreshold:
                          type: integer
                          default: 60
                          description: Number of batches to accumulate before triggering the OPTIMIZE
                        fileSizeThreshold:
                          type: string
                          default: 100MB
                          description: File size to target when running OPTIMIZE
                      default:
                        batchThreshold: 60
                        fileSizeThreshold: 100MB
                    snapshotExpirationSettings:
                      type: object
                      description: Configuration for EXPIRE SNAPSHOTS (table transaction log cutoff)
                      properties:
                        batchThreshold:
                          type: integer
                          default: 60
                          description: Number of batches to accumulate triggering EXPIRE SNAPSHOTS
                        retentionThreshold:
                          type: string
                          default: 6h
                          description: Maximum age of records in the transaction log to keep
                      default:
                        batchThreshold: 60
                        retentionThreshold: 6h
                    orphanFilesExpirationSettings:
                      type: object
                      description: Configuration for EXPIRE ORPHAN FILES (cleanup of files no longer referenced by Iceberg snapshots)
                      properties:
                        batchThreshold:
                          type: integer
                          default: 60
                          description: Number of batches to accumulate before triggering EXPIRE ORPHAN FILES
                        retentionThreshold:
                          type: string
                          default: 6h
                          description: Maximum age of files to keep while running this procedure
                      default:
                        batchThreshold: 60
                        retentionThreshold: 6h
                    analyzeSettings:
                      type: object
                      description: Configuration for ANALYZE (full refresh of extended statistics on the target)
                      properties:
                        batchThreshold:
                          type: integer
                          default: 60
                          description: Number of batches to accumulate before running the ANALYZE query.
                        includedColumns:
                          type: array
                          description: Columns to include in the ANALYZE query. If empty, ALL columns will be included.
                          items:
                            type: string
                          default: []
                      default:
                        batchThreshold: 60
                        includedColumns: []                        
                    targetTableName:
                      type: string
                      description: Name of the target table in the Iceberg catalog. Must be fully qualified as catalog.schema.table
                    sinkCatalogSettings:
                      type: object
                      description: Connection settings for Iceberg REST Catalog for the sink (target). This is used by watermarking process.
                      properties:
                        namespace:
                          type: string
                        warehouse:
                          type: string
                        catalogUri:
                          type: string
                stagingDataSettings:
                  type: object
                  properties:
                    dataLocation:
                      type: string
                      description: Option data location override. Only use this setting for debugging and never in production environments.
                    maxRowsPerFile:
                      type: integer
                      description: The maximum number of rows per each data file in the staging table.
                      default: 10000
                    tableNamePrefix:
                      type: string
                      description: Prefix for staging tables created by Arcane. Must be UNIQUE in the WAREHOUSE scope.
                    catalog:
                      type: object
                      description: Settings for Iceberg REST Catalog used for staging tables
                      properties:
                        catalogName:
                          type: string
                        schemaName:
                          type: string
                        warehouse:
                          type: string
                        catalogUri:
                          type: string
                fieldSelectionRule:
                  type: object
                  description: Use this to control which fields from source are streamed to target.
                  properties:
                    ruleType:
                      type: string
                      description: INCLUDE will only use fields provided. You must specify mandatory fields like ARCANE_MERGE_KEY as well. EXCLUDE will exclude provided fields instead. ALL (default) will use all fields without filters.
                      enum:
                        - include
                        - exclude
                        - all
                    fields:
                      type: array
                      items:
                        type: string
                  default:
                    ruleType: all
                    fields: [ ]
            status:
              type: object
              properties:
                phase:
                  type: string
                configurationHash:
                  description: ConfigurationHash represents the hash of the current configuration.
                  type: string
                conditions:
                  type: array
                  items:
                    type: object
                    required:
                      - status
                      - type
                    properties:
                      message:
                        type: string
                      phase:
                        type: string
                      type:
                        type: string
                      status:
                        type: string
                        enum:
                          - "True"
                          - "False"
{{- end }}
